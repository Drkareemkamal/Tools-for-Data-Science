{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drkareemkamal/Tools-for-Data-Science/blob/main/Peer_to_Peer_assginment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oLLiVi4aS53"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0105EN-SkillsNetwork/labs/Module2/images/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcMCvd12aS55"
      },
      "source": [
        "#### Add your code below following the instructions given in the course\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools for Data Science peer-graded Assignment"
      ],
      "metadata": {
        "id": "oiGnBA2tfvB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "cO11BmE6gB6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## list of data science languages :-\n",
        "\n",
        "* Python\n",
        "* R languages\n",
        "* SQL\n"
      ],
      "metadata": {
        "id": "mCqv-la6gEGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## list of data science libraries :-\n",
        "\n",
        "1. Scientific computing libraries in python. such as (Pandas & Numpy)\n",
        "2. Visualization libraries in python such as (Matplotlib & Seaborn)\n",
        "3. High-Level Machine and Deep Learning such as (Scikit learn & Keras)\n",
        "4. Deep Learning libraries such as (Tensorflow and PyTorch)\n",
        "5. Other Libraries such as (Scala , Vegas , Big DL\n",
        "6. R libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "ZEjjkzC8gZoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tables of Data science tools :-\n",
        "Tool Name     | Description                                                 | Key Features\n",
        "------------- | ----------------------------------------------------------- | ---------------------------------------\n",
        "Python        | A popular programming language for Data Science.             | Extensive libraries (NumPy, Pandas, Matplotlib, scikit-learn), wide community support, integration with other tools.\n",
        "R             | A statistical programming language for Data Science.         | Rich statistical and graphical capabilities, extensive package ecosystem (tidyverse, dplyr, ggplot2).\n",
        "SQL           | A language for managing and analyzing relational databases.  | Efficient querying and manipulation of structured data, widely used in data exploration and extraction.\n",
        "Jupyter Notebook | An open-source web application for interactive coding and documentation. | Allows combining code, text, and visualizations, supports multiple languages.\n",
        "RStudio       | An integrated development environment (IDE) for R.            | Code editor, debugging tools, package management, integrated documentation and visualization.\n",
        "Tableau       | A popular data visualization tool.                           | Drag-and-drop interface, interactive dashboards, supports various data sources, extensive visualization options.\n",
        "Power BI      | A business intelligence tool for data visualization.         | Interactive dashboards, data exploration, integration with multiple data sources, collaboration features.\n",
        "Apache Hadoop | A distributed processing framework for big data.             | Scalable, fault-tolerant, supports distributed storage and processing of large datasets.\n",
        "Apache Spark  | A fast and general-purpose cluster computing system.         | In-memory processing, supports distributed computing, integration with various data sources.\n",
        "TensorFlow    | An open-source machine learning framework by Google.         | Deep learning, neural networks, model deployment, support for multiple programming languages.\n",
        "PyTorch       | An open-source machine learning framework by Facebook.       | Dynamic neural networks, deep learning, GPU acceleration.\n",
        "scikit-learn  | A Python library for machine learning.                       | Various algorithms (classification, regression, clustering), pre-processing, model evaluation, feature selection.\n",
        "Keras         | A high-level neural networks API (built on TensorFlow).      | Simplified interface, easy model prototyping, supports multiple backends (including TensorFlow).\n",
        "H2O.ai        | An open-source machine learning platform.                    | Distributed computing, automatic feature engineering, model interpretation, deployment.\n",
        "Apache Kafka  | A distributed streaming platform.                             | High-throughput, fault-tolerant, real-time data processing, supports pub-sub messaging.\n",
        "Docker        | A platform for containerization and deployment.              | Isolation, reproducibility, easy deployment of Data Science environments.\n",
        "Git           | A version control system for tracking code changes.           | Collaboration, code history management, branching, merging.\n",
        "Amazon Web Services (AWS) | Cloud computing services.                            | Storage, computing, data processing, machine learning, scalable infrastructure.\n",
        "Microsoft Azure | Cloud computing services.                                | Storage, computing, data processing, machine learning, scalable infrastructure.\n"
      ],
      "metadata": {
        "id": "T7NPkUVhgmsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arithmetic Expressions Examples\n",
        "\n",
        "Arithmetic expressions are mathematical expressions that involve numbers and operators. They can be used to perform calculations and solve mathematical problems. Here are some examples of arithmetic expressions:\n",
        "\n",
        "1. Addition: You can use the `+` operator to add numbers together. For example:\n",
        "   - `2 + 3` evaluates to `5`\n",
        "   - `10 + 5.5` evaluates to `15.5`\n",
        "\n",
        "2. Subtraction: The `-` operator can be used for subtraction. For example:\n",
        "   - `7 - 4` evaluates to `3`\n",
        "   - `10.5 - 2.3` evaluates to `8.2`\n",
        "\n",
        "3. Multiplication: The `*` operator is used for multiplication. For example:\n",
        "   - `4 * 5` evaluates to `20`\n",
        "   - `2.5 * 3.5` evaluates to `8.75`\n",
        "\n",
        "4. Division: The `/` operator is used for division. For example:\n",
        "   - `10 / 2` evaluates to `5`\n",
        "   - `15.6 / 3.2` evaluates to `4.875`\n",
        "\n",
        "5. Exponentiation: The `**` operator is used for exponentiation. For example:\n",
        "   - `2 ** 3` evaluates to `8` (2 raised to the power of 3)\n",
        "   - `5 ** 0.5` evaluates to `2.236` (square root of 5)\n"
      ],
      "metadata": {
        "id": "aDw1ZZdCnqDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply two numbers\n",
        "num1 = 4\n",
        "num2 = 7\n",
        "product = num1 * num2\n",
        "print(\"The product of\", num1, \"and\", num2, \"is:\", product)\n",
        "\n",
        "# Add two numbers\n",
        "num3 = 10\n",
        "num4 = 3\n",
        "sum = num3 + num4\n",
        "print(\"The sum of\", num3, \"and\", num4, \"is:\", sum)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIGcwkNHnY8G",
        "outputId": "8cafc33e-2d14-40b4-d6b7-ff979e17b083"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The product of 4 and 7 is: 28\n",
            "The sum of 10 and 3 is: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert minutes to hours\n",
        "minutes = 150\n",
        "hours = minutes / 60\n",
        "print(minutes, \"minutes is equal to\", hours, \"hours.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX4qJqbBn7j3",
        "outputId": "60f1ceb0-5326-4e41-e9cd-3918890d3a29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150 minutes is equal to 2.5 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives\n",
        "\n",
        "The objectives of this project are as follows:\n",
        "\n",
        "1. Collect and preprocess the dataset: Acquire the necessary data for analysis and apply preprocessing techniques such as cleaning, handling missing values, and data transformation.\n",
        "\n",
        "2. Perform exploratory data analysis (EDA): Analyze the dataset to gain insights, identify patterns, and understand the relationships between variables. Visualize the data using plots, charts, and statistical summaries.\n",
        "\n",
        "3. Build predictive models: Develop machine learning models to predict specific outcomes or classify data based on patterns and relationships discovered during the EDA phase. This may involve feature engineering, model selection, and parameter tuning.\n",
        "\n",
        "4. Evaluate model performance: Assess the performance of the predictive models using appropriate evaluation metrics, such as accuracy, precision, recall, or mean squared error. Compare the performance of different models and select the best one.\n",
        "\n",
        "5. Deploy the model: Deploy the selected model into a production environment or integrate it into an application for real-world use. Ensure scalability, reliability, and efficiency of the deployed model.\n",
        "\n",
        "6. Monitor and refine: Continuously monitor the performance of the deployed model and collect feedback. Incorporate improvements, fine-tune parameters, or update the model as needed to ensure optimal performance over time.\n",
        "\n",
        "7. Document and communicate: Document the entire data science process, including data sources, preprocessing steps, model development, and evaluation. Communicate the findings, insights, and recommendations to stakeholders in a clear and understandable manner.\n",
        "\n",
        "These objectives provide a high-level overview of the tasks involved in a typical data science project. Adapt them based on the specific requirements and goals of your project.\n"
      ],
      "metadata": {
        "id": "9Zh9Tg12oaI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Dr.Kareem Kamal"
      ],
      "metadata": {
        "id": "P7SPnf7Kop_u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22l03Rw-oSqG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "name": ""
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}